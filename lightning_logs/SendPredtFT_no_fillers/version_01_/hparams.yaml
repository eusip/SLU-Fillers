accumulate_grad_batches: 1
adafactor: false
adam_epsilon: 1.0e-08
attention_dropout: null
cache_dir: .cache
check_val_every_n_epoch: 1
config_name: ''
data_dir: data
dataset_name: no_fillers
decoder_layerdrop: null
do_predict: false
dropout: null
encoder_layerdrop: null
eval_batch_size: 8
experiment: SentPredFT
fast_dev_run: false
gpus: 0
gradient_clip_val: 1.0
learning_rate: 5.0e-05
line_by_line: true
max_epochs: 10
max_seq_length: 512
mlm: false
mlm_path: ./output/best_tfmr
mlm_probability: 0.15
model_name_or_path: bert-base-cased
num_workers: 8
output_dir: output
overwrite_cache: false
pad_to_max_length: true
precision: 32
preprocessing_num_workers: 8
seed: 42
tokenizer_name: ''
train_batch_size: 8
warmup_steps: 0
weight_decay: 0.0
